<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>research on Chiara Aina</title>
    <link>https://chiaraaina.github.io/research/</link>
    <description>Recent content in research on Chiara Aina</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 07 Jan 2020 16:47:30 +0000</lastBuildDate><atom:link href="https://chiaraaina.github.io/research/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Tailored Stories</title>
      <link>https://chiaraaina.github.io/research/tailored_stories/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://chiaraaina.github.io/research/tailored_stories/</guid>
      <description>To what extent is it possible to manipulate beliefs by providing interpretations of unknown events? I characterize the feasible posteriors across signals when the agent is exposed to a set of models to interpret observable signals and adopts the model that best fits what is observed. Because each signal could trigger the adoption of a different model, posteriors across signal realizations might not average to the prior. The scope of persuasion is large, even for a persuader who does not control or know the signal the agent observes.</description>
    </item>
    
    <item>
      <title>Contingent Belief Updating</title>
      <link>https://chiaraaina.github.io/research/contingent/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://chiaraaina.github.io/research/contingent/</guid>
      <description>We study how contingent thinking – that is, reasoning through all possible contingencies without knowing which is realized – affects belief updating. According to the Bayesian benchmark, beliefs updated after exposure to new information should be equivalent to beliefs assessed for the contingency of receiving such information. Using an experiment, we decompose the effect of contingent thinking on belief updating into two components: (1) hypothetical thinking (updating on a piece of not-yet-observed information) and (2) contrast reasoning (comparing multiple contingencies during the updating process).</description>
    </item>
    
    <item>
      <title>Weighting Competing Models</title>
      <link>https://chiaraaina.github.io/research/weighting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://chiaraaina.github.io/research/weighting/</guid>
      <description>This project aims to understand how we update beliefs in the presence of competing models. It is common to be in situations where different models could explain the data. How do people learn from data in these situations? Do they select only one model to update beliefs, or do they form posteriors by weighting the predictions of the competing models? Our experimental design allows us to isolate the weights subjects place on different models and to compare them with the theoretical predictions.</description>
    </item>
    
    <item>
      <title>Competing in Tailores Stories</title>
      <link>https://chiaraaina.github.io/research/competing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://chiaraaina.github.io/research/competing/</guid>
      <description>We study the competition among senders in the supply of models. For example, politicians compete to supply voters with models to interpret data on immigration or economic outcomes; brokers might want clients to interpret the same firm’s performance differently, driven by different incentives. The senders&amp;rsquo; strategies and the receiver&amp;rsquo;s beliefs vary with respect to the incentives of the parties involved</description>
    </item>
    
  </channel>
</rss>
