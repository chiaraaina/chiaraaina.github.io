<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>research on Chiara Aina</title>
    <link>https://chiaraaina.github.io/research/</link>
    <description>Recent content in research on Chiara Aina</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 07 Jan 2020 16:47:30 +0000</lastBuildDate><atom:link href="https://chiaraaina.github.io/research/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Tailored Stories</title>
      <link>https://chiaraaina.github.io/research/tailored_stories/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://chiaraaina.github.io/research/tailored_stories/</guid>
      <description>I study the problem of persuading a boundedly rational agent without controlling or knowing the piece of information she observes. Persuasion occurs by providing models whereby the persuader can communicate ways of interpreting observable signals. The key assumption is that the agent adopts the model that best fits what is observed, given her initial beliefs, and takes the action that maximizes her expected utility under the adopted model. I characterize the extent of belief manipulability in this setting and show that the agent may hold inconsistent beliefs across signal realizations &amp;mdash; posterior beliefs across realizations do not average to the prior &amp;mdash; because each signal may trigger the adoption of a different model.</description>
    </item>
    
    <item>
      <title>Contingent Belief Updating</title>
      <link>https://chiaraaina.github.io/research/contingent/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://chiaraaina.github.io/research/contingent/</guid>
      <description>We study how contingent thinking – that is, reasoning through all possible contingencies without knowing which is realized – affects belief updating. According to the Bayesian benchmark, beliefs updated after exposure to new information should be equivalent to beliefs assessed for the contingency of receiving such information. Using an experiment, we decompose the effect of contingent thinking on belief updating into two components: (1) hypothetical thinking (updating on a piece of not-yet-observed information) and (2) contrast reasoning (comparing multiple contingencies during the updating process).</description>
    </item>
    
    <item>
      <title>Weighting Competing Narratives</title>
      <link>https://chiaraaina.github.io/research/weighting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://chiaraaina.github.io/research/weighting/</guid>
      <description>This project aims to understand how we update beliefs in the presence of competing narratives. It is common to be in situations where we are uncertain about how the data we observe was generated: different competing narratives could explain the data. How do people learn in these settings? Do they select only one narrative to update beliefs, or do they form posteriors that place non-zero weights on all narratives? Selecting only one narrative leads to more extreme beliefs, while weighting different narratives allows for more nuanced conclusions.</description>
    </item>
    
  </channel>
</rss>
